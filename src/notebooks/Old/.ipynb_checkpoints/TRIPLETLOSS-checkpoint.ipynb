{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# 1. Complete make_one_shot_task\n",
    "# 2. Complete test one shot task\n",
    "# 3. Complete plotting\n",
    "# 4. See if using attention with some static probabilities help the detection of spoofing\n",
    "# 5. Look at triple loss and computing it\n",
    "# 6. CNN and attention to top of the book - https://towardsdatascience.com/self-attention-in-computer-vision-2782727021f6\n",
    "    #Propose probabilities learnt through an LSTM network \n",
    "# 7. Higher prediction probabilities for top of book\n",
    "    #https://machinelearningmastery.com/how-to-score-probability-predictions-in-python/\n",
    "# 8. Fuck with data to get the desired result -b rebuild project\n",
    "# 9. Clean up code, make fancy plots, write comments and so on\n",
    "# 10. See if using LSTM to learn probabilities for attention would work \n",
    "# 11. Learn Families of classes for spoofing \n",
    "# 12. Custom loss function for family of identifications\n",
    "# 13. Cross Modal for price and qty - https://iclr.cc/virtual/poster_B1lJzyStvS.html\n",
    "# 14. Mutual information for either layering or other task - https://iclr.cc/virtual/poster_rkxoh24FPH.html, https://openreview.net/forum?id=rkxoh24FPH\n",
    "# 15. Time seires with triplet leraning - https://papers.nips.cc/paper/8713-unsupervised-scalable-representation-learning-for-multivariate-time-series.pdf\n",
    "# 16. Quadraple Learning - https://www.youtube.com/watch?v=_o2SLgjejAE\n",
    "# 17. Add 13/14/15/16 for the work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RESULTS\n",
    "1. No-Change Unnormalised Loss : 0.012634731829166412\n",
    "2. Normalised Loss without anchor normalisation : 0.5267388820648193\n",
    "3. Normalised Loss with anchor : 0.20129983127117157"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "from skimage.util.shape import view_as_windows\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "from tcn import TCN, tcn_full_summary\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Layer, Lambda, Flatten\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "project_path = os.path.abspath(os.path.join('../..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "if project_path not in sys.path:\n",
    "    sys.path.append(project_path)\n",
    "    \n",
    "#print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "nb_classes=2\n",
    "cols, rows = 2, 30\n",
    "input_shape = (cols, rows, 1)\n",
    "volume_imbalace = 0.1\n",
    "evaluate_every = 50 # interval for evaluating on one-shot tasks\n",
    "batch_size = 512\n",
    "n_iter = 500 # No. of training iterations\n",
    "n_val = 250 # how many one-shot tasks to validate on\n",
    "num_frames = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Draw Picture of your data like CRIMY\n",
    "#2. Loop through all the data and create a set with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goog_train = np.load(project_path + '/data/train/20160901/SPY_EDGX.npy')\n",
    "goog_test = np.load(project_path + '/data/train/20160901/GOOG_EDGX.npy')\n",
    "\n",
    "model_path = project_path + '/weights/spoof'\n",
    "model_cp_path = project_path + '/check_point/spoof'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_cleansed_data(lob, width=num_frames):\n",
    "    min_max_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    quantile_transformer = QuantileTransformer()\n",
    "\n",
    "    # As evidenced by above, we can technically select all in the second axis as there is only 1 element. However, \n",
    "    # because we need a 2d input we make it 0. The 3rd axis is side so we need this\n",
    "    lob_qty_buy = pd.DataFrame(lob['quantity'][:,0,0,0:15])\n",
    "    max_buy = np.amax(lob_qty_buy, axis=1)\n",
    "    lob_qty_buy = lob_qty_buy.replace(0, np.NaN)\n",
    "    avg_buy = lob_qty_buy.mean().mean()\n",
    "    vol_sum_buy = lob_qty_buy.sum(axis=1)\n",
    "    \n",
    "    lob_qty_sell = pd.DataFrame(lob['quantity'][:,0,1,0:15])\n",
    "    max_sell = np.amax(lob_qty_sell, axis=1)\n",
    "    lob_qty_sell = lob_qty_sell.replace(0, np.NaN)\n",
    "    avg_sell = lob_qty_sell.mean().mean()\n",
    "    vol_sum_sell = lob_qty_sell.sum(axis=1)\n",
    "    \n",
    "    vol_imbalance = (vol_sum_buy - vol_sum_sell) / (vol_sum_buy + vol_sum_sell)\n",
    "    \n",
    "    label_df = pd.concat([vol_imbalance, pd.Series(lob['action'].ravel()), pd.Series(lob['side'].ravel()), \n",
    "                         max_buy, max_sell], axis=1)\n",
    "    label_df[5] = label_df[0].diff() # Change in the values of the two states of OB (We take diff of prev row)\n",
    "    label_df[6] = 0\n",
    "  \n",
    "    label_df[6] = np.where(((label_df[1] == 2) & (label_df[2] == 'B') & (np.abs(label_df[5]) > volume_imbalace) & \n",
    "                            (label_df[3] > avg_buy)), 1, \n",
    "                             np.where(((label_df[1] == 2) & (label_df[2] == 'S') & \n",
    "                                       (np.abs(label_df[5]) > volume_imbalace) &\n",
    "                                       (label_df[4] > avg_sell)), 2, label_df[6].values))\n",
    "    label_df = label_df.iloc[width-1:]\n",
    "    Y_labels = label_df[6].reset_index(drop=True)\n",
    "   \n",
    "    # Normalise positive samples\n",
    "    # these array manipulations are to get a final array where b-s in same array group\n",
    "    lob_n, d, w, h = lob['quantity'].shape\n",
    "    b_qty = lob['quantity'][:,0,0,:]\n",
    "    s_qty = lob['quantity'][:,0,1,:]\n",
    "    lob_qty = np.stack((b_qty, s_qty), axis=2)\n",
    "\n",
    "    lob_qty = lob_qty.reshape(-1,1)\n",
    "   # lob_qty = min_max_scaler.fit_transform(lob_qty)\n",
    "    lob_qty = lob_qty.reshape(lob_n, h, w)\n",
    "    \n",
    "    b_price = lob['price'][:,0,0,:]\n",
    "    s_price = lob['price'][:,0,1,:]\n",
    "    lob_price = np.stack((b_price, s_price), axis=2)\n",
    "\n",
    "    lob_price = lob_price.reshape(-1,1)\n",
    "   # lob_price = quantile_transformer.fit_transform(lob_price)\n",
    "    lob_price = lob_price.reshape(lob_n, h, w)\n",
    "\n",
    "\n",
    "    lob_states = np.stack((lob_qty, lob_price), axis=-1)\n",
    "    lob_states = lob_states.reshape(lob_n, h, w, 2)\n",
    "    lob_states = view_as_windows(lob_states,(width,1,1,1))[...,0,0,0].transpose(0,4,1,2,3)\n",
    "    \n",
    "    print(lob_states.shape)\n",
    "    print(Y_labels.shape)\n",
    "    return lob_states, Y_labels\n",
    "\n",
    "X_train, Y_train = retrieve_cleansed_data(goog_train)\n",
    "X_test, Y_test = retrieve_cleansed_data(goog_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(shape, name=None, dtype=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer weights with mean as 0.0 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.0, scale = 1e-2, size = shape)\n",
    "\n",
    "def initialize_bias(shape, name=None, dtype=None):\n",
    "    \"\"\"\n",
    "        The paper, http://www.cs.utoronto.ca/~gkoch/files/msc-thesis.pdf\n",
    "        suggests to initialize CNN layer bias with mean as 0.5 and standard deviation of 0.01\n",
    "    \"\"\"\n",
    "    return np.random.normal(loc = 0.5, scale = 1e-2, size = shape)\n",
    "\n",
    "# Intialize bias with mean 0.0 and standard deviation of 10^-2\n",
    "weights = initialize_weights((1000,1))\n",
    "sns.distplot(weights)\n",
    "plt.title(\"Plot of weights initialized, with mean of 0.0 and standard deviation of 0.01\")\n",
    "\n",
    "# Intialize bias with mean 0.5 and standard deviation of 10^-2\n",
    "bias = initialize_bias((1000,1))\n",
    "sns.distplot(bias)\n",
    "plt.title(\"Plot of biases initialized, with mean of 0.0 and standard deviation of 0.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletLossLayer(Layer):\n",
    "    def __init__(self, alpha, **kwargs):\n",
    "        self.alpha = alpha\n",
    "        super(TripletLossLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def triplet_loss(self, inputs):\n",
    "        anchor, positive, negative = inputs\n",
    "\n",
    "        hardest_positive_dist = tf.reduce_max(tf.square(tf.subtract(anchor, positive)), axis=-1)\n",
    "        tf.summary.scalar(\"hardest_positive_dist\", tf.reduce_mean(hardest_positive_dist))\n",
    "\n",
    "        # shape (batch_size)\n",
    "        hardest_negative_dist = tf.reduce_min(tf.subtract(anchor, negative), axis=-1)\n",
    "        tf.summary.scalar(\"hardest_negative_dist\", tf.reduce_mean(hardest_negative_dist))\n",
    "    \n",
    "        # Combine biggest d(a, p) and smallest d(a, n) into final triplet loss\n",
    "        triplet_loss = tf.maximum(hardest_positive_dist - hardest_negative_dist + self.alpha, 0.0)\n",
    "        # Get final mean triplet loss\n",
    "        triplet_loss = tf.reduce_mean(triplet_loss)\n",
    "        return triplet_loss\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        loss = self.triplet_loss(inputs)\n",
    "        self.add_loss(loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_model(frames, h, w, c, input_shape, dimensions, include_top=False, pooling=None, classes=1):  \n",
    "    inp = Input(shape=(frames, h, w, c))\n",
    "    out = Lambda(lambda y: K.reshape(y, (-1, h, w, c)))(inp)\n",
    "    out = Conv2D(32, kernel_size=(1,1), activation='relu', strides=1, padding=\"same\", input_shape=input_shape,\n",
    "                   use_bias = True, kernel_initializer=initialize_weights, bias_initializer=initialize_bias)(out)\n",
    "   # out = MaxPooling2D()(out)\n",
    "    out = Conv2D(64, kernel_size=(3,3), activation='relu', strides=1, padding=\"same\",\n",
    "                   use_bias = True, kernel_initializer=initialize_weights, bias_initializer=initialize_bias)(out)\n",
    "    out = Conv2D(128, kernel_size=(1,1), activation='relu', strides=1, padding=\"same\",\n",
    "                   use_bias = True, kernel_initializer=initialize_weights, bias_initializer=initialize_bias)(out)\n",
    "    num_features_cnn = np.prod(K.int_shape(out)[1:])\n",
    "    out = Lambda(lambda y: K.reshape(y, (-1, num_frames, num_features_cnn)))(out)\n",
    "    out = TCN(nb_filters=128, return_sequences=True, padding='same')(out)\n",
    "    out = Flatten()(out)\n",
    "    out = Dense(128, activation=None, kernel_regularizer=l2(1e-3), kernel_initializer='he_uniform')(out)    \n",
    "    return Model(inputs=inp, outputs=out)\n",
    "\n",
    "\n",
    "def triplets_model(input_shape, embedding, include_top=False, pooling=None):\n",
    "\n",
    "    anchor_input = Input(shape=input_shape, name='anchor_input')\n",
    "    positive_input = Input(shape=input_shape, name='positive_input')\n",
    "    negative_input = Input(shape=input_shape, name='negative_input')\n",
    "\n",
    "    # Get the embedded values\n",
    "    encoded_a = embedding(anchor_input)\n",
    "    encoded_p = embedding(positive_input)\n",
    "    encoded_n = embedding(negative_input)\n",
    "    \n",
    "    #TripletLoss Layer\n",
    "    loss_layer = TripletLossLayer(alpha=0.2, name='triplet_loss_layer')([encoded_a,encoded_p,encoded_n])\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    triplet_net = Model(inputs=[anchor_input,positive_input,negative_input],outputs=loss_layer)\n",
    "    \n",
    "    return triplet_net\n",
    "\n",
    "build_embedding = embedding_model(num_frames, 30, 2, 2, input_shape=(num_frames, 30, 2, 2), dimensions=60)\n",
    "build_triplet = triplets_model(input_shape=(num_frames, 30, 2, 2), embedding=build_embedding)\n",
    "optimizer = Adam(lr = 0.00006)\n",
    "build_triplet.compile(loss=None,optimizer=optimizer)\n",
    "build_embedding.summary()\n",
    "build_triplet.summary()\n",
    "print(build_triplet.metrics_names)\n",
    "tcn_full_summary(build_embedding, expand_residual_blocks=False)\n",
    "plot_model(build_embedding, 'multi_input_and_output_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing on an untrained network\n",
    "probs, yprob = compute_probs(build_embedding ,X_test[:5,:,:,:,:], Y_test[:5])\n",
    "fpr, tpr, thresholds,auc = compute_metrics(probs, yprob)\n",
    "draw_roc(fpr, tpr,thresholds)\n",
    "draw_interdist(build_embedding, n_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Triplet Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplet_batch_spoof(batch_size, lob_states, labels):\n",
    "    n_examples, t, h, w, d = lob_states.shape\n",
    "    triplets = [np.zeros((batch_size, t, h, w, d)) for i in range(3)]\n",
    "    labels_u = labels[labels==0]\n",
    "    labels_b = labels[labels==1]\n",
    "    labels_s = labels[labels==2]\n",
    "    for i in range(batch_size):\n",
    "        if (i%5==0):\n",
    "            idx_a = labels_b.sample(1)\n",
    "            idx_p = labels_b.sample(1)\n",
    "            idx_n = labels_s.sample(1)\n",
    "        elif (i%5==1):\n",
    "            idx_a = labels_b.sample(1)\n",
    "            idx_p = labels_b.sample(1)\n",
    "            idx_n = labels_u.sample(1)\n",
    "        elif (i%5==2):\n",
    "            idx_a = labels_s.sample(1)\n",
    "            idx_p = labels_s.sample(1)\n",
    "            idx_n = labels_b.sample(1)\n",
    "        elif (i%5==3):\n",
    "            idx_a = labels_s.sample(1)\n",
    "            idx_p = labels_s.sample(1)\n",
    "            idx_n = labels_u.sample(1)\n",
    "        elif (i%5==4):\n",
    "            idx_a = labels_u.sample(1)\n",
    "            idx_p = labels_u.sample(1)\n",
    "            idx_n = labels_b.sample(1)\n",
    "        else:\n",
    "            idx_a = labels_u.sample(1)\n",
    "            idx_p = labels_u.sample(1)\n",
    "            idx_n = labels_s.sample(1)\n",
    "   \n",
    "        triplets[0][i,:,:,:,:] = lob_states[idx_a]\n",
    "        triplets[1][i,:,:,:,:] = lob_states[idx_p]\n",
    "        triplets[2][i,:,:,:,:] = lob_states[idx_n]\n",
    "        \n",
    "    return [triplets[0], triplets[1], triplets[2]]\n",
    "    \n",
    "#get_triplet_batch_spoof(2, X_train, Y_train)\n",
    "\n",
    "def triplet_generator(batch_size, positive_samples, neg_train, anchor):\n",
    "    while True:\n",
    "        inputs, targets = get_triplet_batch(batch_size, positive_samples, neg_train, anchor)\n",
    "        label = None\n",
    "        yield ({'anchor_input': inputs[0], 'positive_input': inputs[1], 'negative_input': inputs[2]},\\\n",
    "               [targets[0], targets[1], targets[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training process!!\")\n",
    "print(\"-------------------------------------\")\n",
    "t_start = time.time()\n",
    "n_iteration=0\n",
    "#dummy_target = [np.zeros((batch_size,15)) for i in range(3)]\n",
    "for i in range(1, n_iter+1):\n",
    "    triplets = get_triplet_batch_spoof(batch_size, X_train, Y_train)\n",
    "    loss = build_triplet.train_on_batch(triplets, None)\n",
    "    n_iteration += 1\n",
    "    if i % evaluate_every == 0:\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"[{3}] Time for {0} iterations: {1:.1f} mins, Train Loss: {2}\"\\\n",
    "              .format(i, (time.time()-t_start)/60.0,loss,n_iteration))\n",
    "        probs, yprob = compute_probs(build_embedding, X_test[:n_val,:,:,:,:], Y_test[:n_val])\n",
    "        fpr, tpr, thresholds,auc = compute_metrics(probs, yprob)\n",
    "        draw_roc(fpr, tpr, thresholds)\n",
    "        draw_interdist(build_embedding, n_iteration)\n",
    "       # print(\"Probability \" + str(probs))\n",
    "       # print(\"YProbs \" + str(yprob))\n",
    "        #fpr, tpr, thresholds,auc = compute_metrics(probs,yprob)\n",
    "        #draw_roc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation / Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "\n",
    "def compute_dist(a,b):\n",
    "    return np.sum(np.square(a-b))\n",
    "\n",
    "def compute_probs(network,X,Y):\n",
    "    '''\n",
    "    Input\n",
    "        network : current NN to compute embeddings\n",
    "        X : tensor of shape (m, num_frame, h, w, 1) containing pics to evaluate\n",
    "        Y : tensor of shape (m,) containing true class\n",
    "        \n",
    "    Returns\n",
    "        probs : array of shape (m,m) containing distances\n",
    "    \n",
    "    '''\n",
    "    m = X.shape[0]\n",
    "    nbevaluation = int(m*(m-1)/2)\n",
    "    probs = np.zeros((nbevaluation))\n",
    "    y = np.zeros((nbevaluation))\n",
    "    \n",
    "    #Compute all embeddings for all pics with current network\n",
    "    embeddings = network.predict(X)\n",
    "    \n",
    "    size_embedding = embeddings.shape[1]\n",
    "    \n",
    "    #For each pics of our dataset\n",
    "    k = 0\n",
    "    for i in range(m-1):\n",
    "            #Against all other images\n",
    "            for j in range(i+1,m-1):\n",
    "                #compute the probability of being the right decision : it should be 1 for right class, 0 for all other classes\n",
    "                probs[k] = -compute_dist(embeddings[i,:],embeddings[j,:])\n",
    "               # print(probs[k])\n",
    "                if (Y[i]==Y[j]):\n",
    "                    y[k] = 1\n",
    "                    #print(\"{3}:{0} vs {1} : {2}\\tSAME\".format(i,j,probs[k],k))\n",
    "                else:\n",
    "                    y[k] = 0\n",
    "                   # print(\"{3}:{0} vs {1} : \\t\\t\\t{2}\\tDIFF\".format(i,j,probs[k],k))\n",
    "                k += 1\n",
    "    return probs,y\n",
    "#probs,yprobs = compute_probs(network,x_test_origin[:10,:,:,:],y_test_origin[:10])\n",
    "\n",
    "def compute_metrics(probs,yprobs):\n",
    "    '''\n",
    "    Returns\n",
    "        fpr : Increasing false positive rates such that element i is the false positive rate of predictions with score >= thresholds[i]\n",
    "        tpr : Increasing true positive rates such that element i is the true positive rate of predictions with score >= thresholds[i].\n",
    "        thresholds : Decreasing thresholds on the decision function used to compute fpr and tpr. thresholds[0] represents no \n",
    "        instances being predicted and is arbitrarily set to max(y_score) + 1\n",
    "        auc : Area Under the ROC Curve metric\n",
    "    '''\n",
    "    # calculate AUC\n",
    "    auc = roc_auc_score(yprobs, probs)\n",
    "    # calculate roc curve\n",
    "    fpr, tpr, thresholds = roc_curve(yprobs, probs)\n",
    "    \n",
    "    return fpr, tpr, thresholds,auc\n",
    "\n",
    "def compute_interdist(network):\n",
    "    '''\n",
    "    Computes sum of distances between all classes embeddings on our reference test image: \n",
    "        d(0,1) + d(0,2) + ... + d(0,9) + d(1,2) + d(1,3) + ... d(8,9)\n",
    "        A good model should have a large distance between all theses embeddings\n",
    "        \n",
    "    Returns:\n",
    "        array of shape (nb_classes,nb_classes) \n",
    "    '''\n",
    "    res = np.zeros((nb_classes,nb_classes))\n",
    "    \n",
    "    ref_images = np.zeros((nb_classes, num_frames, rows, cols, 2))\n",
    "    \n",
    "    #generates embeddings for reference images\n",
    "    for i in range(nb_classes):\n",
    "        ref_images[i,:,:,:] = X_test[i,:,:,:,:]\n",
    "    ref_embeddings = network.predict(ref_images)\n",
    "    \n",
    "    for i in range(nb_classes):\n",
    "        for j in range(nb_classes):\n",
    "            res[i,j] = compute_dist(ref_embeddings[i],ref_embeddings[j])\n",
    "    return res\n",
    "\n",
    "def draw_interdist(network, n_iteration):\n",
    "    interdist = compute_interdist(network)\n",
    "    \n",
    "    data = []\n",
    "    for i in range(nb_classes):\n",
    "        data.append(np.delete(interdist[i,:],[i]))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('Evaluating embeddings distance from each other after {0} iterations'.format(n_iteration))\n",
    "    ax.set_ylim([0,3])\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Distance')\n",
    "    ax.boxplot(data,showfliers=False,showbox=True)\n",
    "    locs, labels = plt.xticks()\n",
    "    plt.xticks(locs,np.arange(nb_classes))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return array[idx-1],idx-1\n",
    "    else:\n",
    "        return array[idx],idx\n",
    "    \n",
    "def draw_roc(fpr, tpr,thresholds):\n",
    "    #find threshold\n",
    "    targetfpr=1e-3\n",
    "    _, idx = find_nearest(fpr,targetfpr)\n",
    "    threshold = thresholds[idx]\n",
    "    recall = tpr[idx]\n",
    "    \n",
    "    \n",
    "    # plot no skill\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(fpr, tpr, marker='.')\n",
    "    plt.title('AUC: {0:.3f}\\nSensitivity : {2:.1%} @FPR={1:.0e}\\nThreshold={3})'.format(auc,targetfpr,recall,abs(threshold)))\n",
    "    # show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Testing on an untrained network\n",
    "probs, yprob = compute_probs(build_embedding ,X_train[:5000,:,:,:,:], Y_train[:5000])\n",
    "fpr, tpr, thresholds,auc = compute_metrics(probs, yprob)\n",
    "draw_roc(fpr, tpr,thresholds)\n",
    "draw_interdist(build_embedding, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_b = Y_test[Y_test==1]\n",
    "labels_s = Y_test[Y_test==2]\n",
    "X_test[labels_s.index].shape\n",
    "y = labels_s.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing on an untrained network\n",
    "probs, yprob = compute_probs(build_embedding ,X_test[labels_s.index], y)\n",
    "fpr, tpr, thresholds,auc = compute_metrics(probs, yprob)\n",
    "draw_roc(fpr, tpr,thresholds)\n",
    "draw_interdist(build_embedding, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing on an untrained network\n",
    "probs, yprob = compute_probs(build_embedding ,X_train[:2500,:,:,:,:], Y_train[:2500])\n",
    "fpr, tpr, thresholds,auc = compute_metrics(probs, yprob)\n",
    "draw_roc(fpr, tpr,thresholds)\n",
    "draw_interdist(build_embedding, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def power_mean(x, p=-5):\n",
    "    return np.power(np.mean(np.power(x, p)),1/p)\n",
    "\n",
    "def get_s_auc(y_true,y_pred,y_identity):\n",
    "    mask = y_identity==1\n",
    "    s_auc = roc_auc_score(y_true[mask],y_pred[mask])\n",
    "    return s_auc\n",
    "\n",
    "def get_bpsn_auc(y_true,y_pred,y_identity):\n",
    "    mask = (y_identity==1) & (y_true==0) | (y_identity==0) & (y_true==1)\n",
    "    bpsn_auc = roc_auc_score(y_true[mask],y_pred[mask])\n",
    "    return bpsn_auc\n",
    "\n",
    "def get_bspn_auc(y_true,y_pred,y_identity):\n",
    "    mask = (y_identity==1) & (y_true==1) | (y_identity==0) & (y_true==0)\n",
    "    bspn_auc = roc_auc_score(y_true[mask],y_pred[mask])\n",
    "    return bspn_auc\n",
    "\n",
    "def get_total_auc(y_true,y_pred,y_identities):\n",
    "\n",
    "    N = y_identities.shape[1]\n",
    "    saucs = np.array([get_s_auc(y_true,y_pred,y_identities[:,i]) for i in range(N)])\n",
    "    bpsns = np.array([get_bpsn_auc(y_true,y_pred,y_identities[:,i]) for i in range(N)])\n",
    "    bspns = np.array([get_bspn_auc(y_true,y_pred,y_identities[:,i]) for i in range(N)])\n",
    "\n",
    "    M_s_auc = power_mean(saucs)\n",
    "    M_bpsns_auc = power_mean(bpsns)\n",
    "    M_bspns_auc = power_mean(bspns)\n",
    "    rauc = roc_auc_score(y_true,y_pred)\n",
    "\n",
    "\n",
    "    total_auc = M_s_auc + M_bpsns_auc + M_bspns_auc + rauc\n",
    "    total_auc/= 4\n",
    "\n",
    "    return total_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DrawTestImage(network, images, refidx=500):\n",
    "    '''\n",
    "    Evaluate some pictures vs some samples in the test set\n",
    "        image must be of shape(1,w,h,c)\n",
    "    \n",
    "    Returns\n",
    "        scores : resultat des scores de similarits avec les images de base => (N)\n",
    "    \n",
    "    '''\n",
    "    N=4\n",
    "    _, w,h,c = list_of_test[0].shape\n",
    "    nbimages=images.shape[0]\n",
    "    \n",
    "    #generates embedings for given images\n",
    "    image_embedings = network.predict(images)\n",
    "    \n",
    "    #generates embedings for reference images\n",
    "    ref_images = np.zeros((nb_classes,w,h,c))\n",
    "    for i in range(nb_classes):\n",
    "        ref_images[i,:,:,:1] = list_of_test[i][refidx,:,:,:1]\n",
    "    ref_embedings = network.predict(ref_images)\n",
    "            \n",
    "    for i in range(nbimages):\n",
    "        #Prepare the figure\n",
    "        fig=plt.figure(figsize=(16,2))\n",
    "        subplot = fig.add_subplot(1,nb_classes+1,1)\n",
    "        axis(\"off\")\n",
    "        plotidx = 2\n",
    "            \n",
    "        #Draw this image    \n",
    "        #plt.imshow(images[i,:,:,0],vmin=0, vmax=1,cmap='Greys')\n",
    "        plt.matshow(images[i,:,:,0], cmap='gray')\n",
    "        #sns.heatmap(images[i,:,:,0], vmin=0, vmax=5000, cmap='Greens', center=None,\n",
    "           #             robust=False, annot=None, fmt='.2g', annot_kws=None, linewidths=0, linecolor='white', \n",
    "           #             cbar=True, cbar_kws=None, cbar_ax=None, square=False, xticklabels=True, \n",
    "           #             yticklabels=True, mask=None, ax=None)\n",
    "        subplot.title.set_text(\"Test image\")\n",
    "            \n",
    "        for ref in range(nb_classes):\n",
    "            #Compute distance between this images and references\n",
    "            dist = compute_dist(image_embedings[i,:],ref_embedings[ref,:])\n",
    "            #Draw\n",
    "            subplot = fig.add_subplot(1,nb_classes+1,plotidx)\n",
    "            axis(\"off\")\n",
    "            #plt.imshow(ref_images[ref,:,:,0],vmin=0, vmax=1,cmap='Greys')\n",
    "            plt.matshow(ref_images[ref,:,:,0], vmin=0, vmax=200000, cmap='gray')\n",
    "            #sns.heatmap(ref_images[ref,:,:,0].reshape(2,30).T, vmin=0, vmax=5000, cmap='Greens', center=None,\n",
    "             #           robust=False, annot=None, fmt='.2g', annot_kws=None, linewidths=0, linecolor='white', \n",
    "              #          cbar=True, cbar_kws=None, cbar_ax=None, square=False, xticklabels=True, \n",
    "               #         yticklabels=True, mask=None, ax=None)\n",
    "            subplot.title.set_text((\"Class {0}\\n{1:.3e}\".format(ref,dist)))\n",
    "            plotidx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    DrawTestImage(build_embedding,np.expand_dims(list_of_train[i][230,:,:,:,:],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full evaluation\n",
    "probs,yprob = compute_probs(build_embedding,X_test,Y_test)\n",
    "fpr, tpr, thresholds,auc = compute_metrics(probs,yprob)\n",
    "draw_roc(fpr, tpr,thresholds)\n",
    "draw_interdist(build_embedding,n_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    DrawTestImage(build_embedding,np.expand_dims(list_of_train[i][680,:,:,:],axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(model_cp_path, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=2)\n",
    "callbacks_list = [checkpoint, early]  # early\n",
    "\n",
    "gen_tr = triplet_generator(batch_size, pos_train, neg_train, spoof_ground_truth.spoof_step1_truth1)\n",
    "\n",
    "history = triplet_model.fit_generator(gen_tr, \n",
    "                              epochs=10, \n",
    "                              verbose=1, \n",
    "                              workers=4,\n",
    "                              steps_per_epoch=200, \n",
    "                              validation_steps=20, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds  = []\n",
    "train_file_names = []\n",
    "for i in range(1, n_iter+1):\n",
    "    inputs, targets = data_generator(32, pos_train, neg_train, spoof_ground_truth.spoof_step1_truth1, 1)\n",
    "    predicts = triplet_model.predict(inputs)\n",
    "    print(predicts[0])\n",
    "    predicts = predicts.tolist()\n",
    "    train_preds += predicts\n",
    "    targets = targets.tolist()\n",
    "    train_file_names += targets\n",
    "train_preds = np.array(train_preds)\n",
    "\n",
    "\n",
    "test_preds  = []\n",
    "test_file_names = []\n",
    "for i in range(1, n_iter+1):\n",
    "    inputs, targets = data_generator(32, pos_val, neg_val, spoof_ground_truth.spoof_step1_truth1, 1)\n",
    "    if i % evaluate_every == 0:\n",
    "        predicts = embedding_model.predict(inputs)\n",
    "        predicts = predicts.tolist()\n",
    "        test_preds += predicts\n",
    "        targets = targets.tolist()\n",
    "        test_file_names += targets\n",
    "test_preds = np.array(test_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "neigh = NearestNeighbors(n_neighbors=6)\n",
    "neigh.fit(train_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_test, neighbors_test = neigh.kneighbors(test_preds)\n",
    "distances_test, neighbors_test = distances_test.tolist(), neighbors_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_te = triplet_generator_new(batch_size, pos_val, neg_val, spoof_ground_truth.spoof_step1_truth1)\n",
    "predictions = triplet_model.embedding_model.predict(gen_te, steps=1)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.legend()\n",
    "# plt.show()\n",
    "def eva_plot(History, epoch):\n",
    "    plt.figure(figsize=(20,10))\n",
    "#     sns.lineplot(range(1, epoch+1), History.history['acc'], label='Train Accuracy')\n",
    "#     sns.lineplot(range(1, epoch+1), History.history['val_acc'], label='Test Accuracy')\n",
    "#     plt.legend(['train', 'validaiton'], loc='upper left')\n",
    "#     plt.ylabel('accuracy')\n",
    "#     plt.xlabel('epoch')\n",
    "#     plt.show()\n",
    "    plt.figure(figsize=(20,10))\n",
    "    sns.lineplot(range(1, epoch+1), History.history['loss'], label='Train loss')\n",
    "    sns.lineplot(range(1, epoch+1), History.history['val_loss'], label='Test loss')\n",
    "    plt.legend(['train', 'validaiton'], loc='upper left')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title(\"Loss Graph\")\n",
    "    plt.show()\n",
    "    \n",
    "eva_plot(history, 4)\n",
    "\n",
    "def val_plot(History, epoch):\n",
    "    plt.figure(figsize=(20,10))\n",
    "#     sns.lineplot(range(1, epoch+1), History.history['acc'], label='Train Accuracy')\n",
    "#     sns.lineplot(range(1, epoch+1), History.history['val_acc'], label='Test Accuracy')\n",
    "#     plt.legend(['train', 'validaiton'], loc='upper left')\n",
    "#     plt.ylabel('accuracy')\n",
    "#     plt.xlabel('epoch')\n",
    "#     plt.show()\n",
    "    plt.figure(figsize=(20,10))\n",
    "    sns.lineplot(range(1, epoch+1), History.history['model_8_loss'], label='Embedding Train loss')\n",
    "    sns.lineplot(range(1, epoch+1), History.history['val_model_8_loss'], label='Embedding Test loss')\n",
    "    plt.legend(['train', 'validaiton'], loc='upper left')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title(\"Loss Graph\")\n",
    "    plt.show()\n",
    "    \n",
    "val_plot(history, 4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss1(y_true, y_pred, alpha=0.4):\n",
    "    print(\"for distance branch, y_pred.shape:  \", y_pred)       # [Batch_dim, vec_dim*3]\n",
    "\n",
    "    vec_len = y_pred.shape.as_list()[-1]\n",
    "\n",
    "    anchor = y_pred[:, :int(vec_len/3)]\n",
    "    positve = y_pred[:, int(vec_len/3):int(vec_len*2/3)]\n",
    "    negative = y_pred[:, int(vec_len*2/3):]\n",
    "\n",
    "    pos_dist = K.sum(K.square(anchor - positve), axis=1)\n",
    "    neg_dist = K.sum(K.square(anchor - negative), axis=1)\n",
    "\n",
    "    loss = K.maximum(0., pos_dist - neg_dist + alpha)\n",
    "\n",
    "    return loss\n",
    "a = tf.compat.v1.random_normal([5, 60], mean=6, stddev=0.1, seed = 1)\n",
    "\n",
    "with tf.compat.v1.Session() as test:\n",
    "    tf.compat.v1.set_random_seed(1)\n",
    "    y_true = (None, None, None)\n",
    "    a = tf.compat.v1.random_normal([5, 60], mean=6, stddev=0.1, seed = 1)\n",
    "    print(a)\n",
    "    p = tf.compat.v1.random_normal([5, 60], mean=1, stddev=1, seed = 1)\n",
    "    n = tf.compat.v1.random_normal([5, 60], mean=3, stddev=4, seed = 1)\n",
    "    merged = concatenate([a, p, n], axis=-1)\n",
    "    y_pred = (tf.compat.v1.random_normal([3, 60], mean=6, stddev=0.1, seed = 1),\n",
    "              tf.compat.v1.random_normal([3, 60], mean=1, stddev=1, seed = 1),\n",
    "              tf.compat.v1.random_normal([3, 60], mean=3, stddev=4, seed = 1), \n",
    "              tf.compat.v1.random_normal([3, 60], mean=3, stddev=4, seed = 1))\n",
    "    loss = triplet_loss1(y_true, merged)\n",
    "    \n",
    "    print(\"loss = \" + str(loss.eval()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_every = 20 # interval for evaluating on one-shot tasks\n",
    "loss_every = 20 # interval for printing loss (iterations)\n",
    "batch_size = 32\n",
    "n_iter = 2\n",
    "N_way = 20 # how many classes for testing one-shot tasks>\n",
    "n_val = 250 # how many one-shot tasks to validate on?\n",
    "best = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "t_start = time.time()\n",
    "for i in range(1, n_iter+1):\n",
    "    (inputs, targets) = get_triplet_batch(batch_size, pos_train, neg_train, spoof_ground_truth.spoof_step1_truth1)\n",
    "    #(inp, tar) = triplet_generator()\n",
    "    loss = triplet_model.model.train_on_batch(inputs, targets)\n",
    "    print(loss)\n",
    "    if i % evaluate_every == 0:\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
    "        print(\"Train Loss: {0}\".format(loss)) \n",
    "        val_acc = test_oneshot(model, N_way, n_val, verbose=True)\n",
    "\n",
    "  \n",
    "        triplet_model.model.save_weights(os.path.join(model_path, 'weights_triplet.{}.h5'.format(i)))\n",
    "        if val_acc >= best:\n",
    "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
    "            best = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "data = [[1,2,3],[4,5,6]]\n",
    "data_np = np.asarray(data, np.float32)\n",
    "\n",
    "data_tf = tf.convert_to_tensor(data_np, np.float32)\n",
    "\n",
    "data_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = triplet_generator(batch_size, pos_train, neg_train, spoof_ground_truth.spoof_step1_truth1)\n",
    "val_generator = triplet_generator(batch_size, pos_val, neg_val, spoof_ground_truth.spoof_step1_truth1)\n",
    "\n",
    "model.fit(generator=train_generator, steps_per_epoch=20, epochs=100,\n",
    "                        validation_data=val_generator,\n",
    "                        validation_steps=10,\n",
    "                        verbose=1) #callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "t_start = time.time()\n",
    "for i in range(1, n_iter+1):\n",
    "    (inputs, targets) = get_triplet_batch(batch_size, pos_train, neg_train, spoof_ground_truth.spoof_step1_truth1)\n",
    "    #(inp, tar) = triplet_generator()\n",
    "    loss = triplet_model.model.train_on_batch(inputs, targets)\n",
    "    print(loss)\n",
    "    if i % evaluate_every == 0:\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
    "        print(\"Train Loss: {0}\".format(loss)) \n",
    "      #  val_acc = test_oneshot(model, N_way, n_val, verbose=True)\n",
    "        triplet_model.model.save_weights(os.path.join(model_path, 'weights_triplet.{}.h5'.format(i)))\n",
    "       # if val_acc >= best:\n",
    "        #    print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
    "         #   best = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training_Pipeline(object):\n",
    "    def __init__(self):\n",
    "        self._birthdate = time.time()\n",
    "        \n",
    "    @staticmethod\n",
    "    def get_batch(batch_size, positive_samples, negative_samples, anchor):\n",
    "        \"\"\"Create batch of n pairs, half same class, half different class\"\"\"\n",
    "        n_examples_p, d, w, h = positive_samples.shape\n",
    "        n_examples_n = negative_samples.shape[0]\n",
    "\n",
    "        # initialize 2 empty arrays for the input image batch\n",
    "        pairs = [np.zeros((batch_size, w, h, 1)) for i in range(2)]\n",
    "\n",
    "        # initialize vector for the targets\n",
    "        targets=np.zeros((batch_size,))\n",
    "\n",
    "        # make one half of it '1's, so 2nd half of batch has same class\n",
    "        targets[batch_size//2:] = 1\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            idx_p = rng.randint(0, n_examples_p)\n",
    "            idx_n = rng.randint(0, n_examples_n)\n",
    "            pairs[0][i,:,:,:] = anchor.reshape(w, h, 1)\n",
    "\n",
    "            if i >= batch_size // 2:\n",
    "                pairs[1][i,:,:,:] = positive_samples[idx_p].reshape(w, h, 1)\n",
    "            else:\n",
    "                pairs[1][i,:,:,:] = negative_samples[idx_n].reshape(w, h, 1)\n",
    "        return pairs, targets\n",
    "    \n",
    "    def make_oneshot_task(self, N, positive_samples, negative_samples, anchor):\n",
    "        \"\"\"Create pairs of test image, support set for testing N way one-shot learning. \"\"\"\n",
    "\n",
    "        n_examples_p, d, w, h = positive_samples.shape\n",
    "        n_examples_n = negative_samples.shape[0]\n",
    "\n",
    "        test_lob = np.asarray([anchor]*N).reshape(N, w, h, 1)\n",
    "\n",
    "       # print(test_lob)\n",
    "\n",
    "        p_index = rng.randint(0, n_examples_p, size=(1,))\n",
    "        n_index = rng.randint(0, n_examples_n, size=(N,))\n",
    "\n",
    "        support_set = negative_samples[n_index]\n",
    "       # print('n_index' + str(n_index))\n",
    "      #  print(support_set[0])\n",
    "      #  print(support_set[1])\n",
    "        support_set[0] = positive_samples[p_index]\n",
    "       # print('zero now')\n",
    "       # print(support_set[0])\n",
    "       # print('one now')\n",
    "      #  print(support_set[1])\n",
    "        support_set = support_set.reshape(N, w, h, 1)\n",
    "\n",
    "        targets = np.zeros((N,))\n",
    "        targets[0] = 1     \n",
    "       # print(targets)\n",
    "        targets, test_lob, support_set = shuffle(targets, test_lob, support_set)\n",
    "        pairs = [test_lob, support_set]\n",
    "        return pairs, targets\n",
    "\n",
    "    def test_oneshot(self, model, N, k, s = \"val\", verbose = 0):\n",
    "        \"\"\"Test average N way oneshot learning accuracy of a siamese neural net over k one-shot tasks\"\"\"\n",
    "        n_correct = 0\n",
    "        inputs = []\n",
    "        targets = []\n",
    "        if verbose:\n",
    "            print(\"Evaluating model on {} random {} way one-shot learning tasks ... \\n\".format(k,N))\n",
    "        for i in range(k):\n",
    "            if s == 'train':\n",
    "                inputs, targets = self.make_oneshot_task(N, pos_train, neg_train, spoof_ground_truth.spoof_step1_truth1)\n",
    "            else:\n",
    "                inputs, targets = self.make_oneshot_task(N, pos_val, neg_val, spoof_ground_truth.spoof_step1_truth1)\n",
    "            probs = model.predict(inputs)\n",
    "            #print(probs)\n",
    "            if np.argmax(probs) == np.argmax(targets):\n",
    "                n_correct+=1\n",
    "        percent_correct = (100.0 * n_correct / k)\n",
    "        if verbose:\n",
    "            print(\"Got an average of {}% {} way one-shot learning accuracy \\n\".format(percent_correct,N))\n",
    "        return percent_correct\n",
    "    \n",
    "    \n",
    "    def generate(batch_size, s=\"train\"):\n",
    "        \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
    "        while True:\n",
    "            pairs, targets = get_batch(batch_size,s)\n",
    "            yield (pairs, targets)\n",
    "\n",
    "training_pipeline = Training_Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of concat image visualization\n",
    "np.set_printoptions(suppress=True)\n",
    "pairs, targets = training_pipeline.make_oneshot_task(15, pos_train, neg_train, spoof_ground_truth.spoof_step1_truth1)\n",
    "plot_oneshot_task(pairs, targets, 15)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting LOBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_oneshot_task(pairs, targets, N): \n",
    "    '''\n",
    "    Only prints out one before last element of a \n",
    "    '''\n",
    "    count = 0\n",
    "    fig, ax = plt.subplots(2, int(N/2), sharex='col', sharey='row', figsize=(15,15))\n",
    "    lob_matrix = []\n",
    "    lob_matrix.append(pairs[0][0])\n",
    "    for j in range(0,int(N)):\n",
    "        lob_matrix.append(pairs[1][j])\n",
    "     \n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    \n",
    "    for i in range(0,2):\n",
    "        for j in range(0,int(N/2)):\n",
    "            sns.heatmap(lob_matrix[count][:,:,0].reshape(2,30).T, vmin=0, vmax=50000, cmap='Greens', center=None,\n",
    "                        robust=False, annot=None, fmt='.2g', annot_kws=None, linewidths=0, linecolor='white', \n",
    "                        cbar=True, cbar_kws=None, cbar_ax=cbar_ax, square=False, xticklabels=True, \n",
    "                        yticklabels=True, mask=None, ax=ax[i, j])\n",
    "            count = count + 1\n",
    "            print(lob_matrix[count][:,:,0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_oneshot_task(pairs, N):\n",
    "    if N/2 == 1:\n",
    "        end = int(N/2)\n",
    "    else:\n",
    "        end = int(N/2)\n",
    "    fig, ax = plt.subplots(2, end, sharex='col', sharey='row', figsize=(15,15))\n",
    "   # im = ax[0, 0].matshow(pairs[0][0].reshape(2,30).T)\n",
    "   # print(pairs[0][1])\n",
    "   # print(pairs[1][0])\n",
    "   # print(pairs[0][0].shape)\n",
    "    data_array = []\n",
    "    data_array.append(pairs[0][0])\n",
    "    #print(data_array[0][:,:,0])\n",
    "    for j in range(0,int(N)):\n",
    "        data_array.append(pairs[1][j])\n",
    "    #print(np.moveaxis(data_array, -1, 0).shape)\n",
    "   # print(data_array[0])\n",
    "    count = 0\n",
    "    initial_pair = 0\n",
    "    for i in range(0,2):\n",
    "        for j in range(0,int(N/2)):\n",
    "            sns.heatmap(data_array[count][:,:,0].reshape(2,30).T, vmin=None, vmax=None, cmap=None, center=None,\n",
    "                robust=False, annot=None, fmt='.2g', annot_kws=None, \n",
    "                linewidths=0, linecolor='white', cbar=True, cbar_kws=None, \n",
    "                cbar_ax=None, square=False, xticklabels='auto',\n",
    "                yticklabels='auto', mask=None, ax=ax[i, j], **kwargs)\n",
    "           # im = ax[i, j].matshow(data_array[count][:,:,0].reshape(2,30).T, cmap='BuPu')\n",
    "            print(i)\n",
    "            print(j)\n",
    "            ax[i, j].text(0.5, 0.5, str((i, j)), fontsize=18, ha='right')\n",
    "            count = count + 1\n",
    "            initial_pair = 1\n",
    "    \n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    print(im)\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_oneshot_task(pairs, N):\n",
    "    if N/2 == 1:\n",
    "        end = int(N/2)\n",
    "    else:\n",
    "        end = int(N/2)\n",
    "    fig, ax = plt.subplots(2, end, sharex='col', sharey='row', figsize=(15,15))\n",
    "   # im = ax[0, 0].matshow(pairs[0][0].reshape(2,30).T)\n",
    "   # print(pairs[0][1])\n",
    "   # print(pairs[1][0])\n",
    "    data_array = pairs[0][0]\n",
    "    for j in range(0,int(N)):\n",
    "        data_array = np.append(data_array, pairs[1][j], axis=-1)\n",
    "    print(data_array)\n",
    "    print(data_array.shape)\n",
    "    print(np.moveaxis(data_array, -1, 0).shape)\n",
    "    count = 0\n",
    "    initial_pair = 0\n",
    "    for i in range(0,2):\n",
    "        for j in range(0,int(end)):\n",
    "            im = ax[i, j].matshow(pairs[initial_pair][count].reshape(2,30).T, cmap='BuPu')\n",
    "            ax[i, j].text(0.5, 0.5, str((i, j)), fontsize=18, ha='right')\n",
    "            count = count + 1\n",
    "            initial_pair = 1\n",
    "    \n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    print(im)\n",
    "    fig.colorbar(im, cax=cbar_ax)\n",
    "    plt.show()\n",
    "#(j-start)*(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_oneshot_task(pairs, N):\n",
    "    fig,(ax1,ax2) = plt.subplots(nrows=1, ncols=N, figsize=(15,15))\n",
    "    ax1.matshow(pairs[0][0].reshape(30,2), cmap='gray')\n",
    "    img = concat_images(pairs[1], N)\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax2.matshow(img,cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "#evaluate_every = 2 # interval for evaluating on one-shot tasks\n",
    "#batch_size = 32\n",
    "#n_iter = 20 # No. of training iterations\n",
    "#N_way = 4 # how many classes for testing one-shot tasks\n",
    "#n_val = 10 # how many one-shot tasks to validate on\n",
    "#best = -1\n",
    "#np.set_printoptions(suppress=True)\n",
    "\n",
    "evaluate_every = 10 # interval for evaluating on one-shot tasks\n",
    "loss_every = 20 # interval for printing loss (iterations)\n",
    "batch_size = 32\n",
    "n_iter = 20000\n",
    "N_way = 20 # how many classes for testing one-shot tasks>\n",
    "n_val = 250 # how many one-shot tasks to validate on?\n",
    "best = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training process!\")\n",
    "print(\"-------------------------------------\")\n",
    "t_start = time.time()\n",
    "for i in range(1, n_iter+1):\n",
    "    inputs, targets = training_pipeline.get_batch(batch_size, pos_train, neg_train,\\\n",
    "                                                     spoof_ground_truth.spoof_step1_truth1)\n",
    "    loss = model.train_on_batch(inputs, targets)\n",
    "    if i % evaluate_every == 0:\n",
    "        print(\"\\n ------------- \\n\")\n",
    "        print(\"Time for {0} iterations: {1} mins\".format(i, (time.time()-t_start)/60.0))\n",
    "        print(\"Train Loss: {0}\".format(loss)) \n",
    "        val_acc = training_pipeline.test_oneshot(model, N_way, n_val, verbose=True)\n",
    "        model.save_weights(os.path.join(model_path, 'weights.{}.h5'.format(i)))\n",
    "        if val_acc >= best:\n",
    "            print(\"Current best: {0}, previous best: {1}\".format(val_acc, best))\n",
    "            best = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(model_path, \"weights.20000.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline model based on nearest neighbors using euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbour_correct(pairs,targets):\n",
    "    \"\"\"returns 1 if nearest neighbour gets the correct answer for a one-shot task\n",
    "        given by (pairs, targets)\"\"\"\n",
    "    L2_distances = np.zeros_like(targets)\n",
    "    for i in range(len(targets)):\n",
    "        L2_distances[i] = np.sum(np.sqrt(pairs[0][i]**2 - pairs[1][i]**2))\n",
    "    if np.argmin(L2_distances) == np.argmax(targets):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nn_accuracy(N_ways,n_trials):\n",
    "    \"\"\"Returns accuracy of NN approach \"\"\"\n",
    "    print(\"Evaluating nearest neighbour on {} unique {} way one-shot learning tasks ...\".format(n_trials,N_ways))\n",
    "\n",
    "    n_right = 0\n",
    "    \n",
    "    for i in range(n_trials):\n",
    "        pairs,targets = training_pipeline.make_oneshot_task(N_ways,pos_val, neg_val,\\\n",
    "                                                            spoof_ground_truth.spoof_step1_truth1)\n",
    "        correct = nearest_neighbour_correct(pairs,targets)\n",
    "        n_right += correct\n",
    "    return 100.0 * n_right / n_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ways = np.arange(1,15,2)\n",
    "resume =  False\n",
    "trials = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accs, train_accs,nn_accs = [], [], []\n",
    "for N in ways:    \n",
    "    val_accs.append(training_pipeline.test_oneshot(model, N, trials, \"val\", verbose=True))\n",
    "    train_accs.append(training_pipeline.test_oneshot(model, N, trials, \"train\", verbose=True))\n",
    "    nn_acc = test_nn_accuracy(N, trials)\n",
    "    nn_accs.append(nn_acc)\n",
    "    print (\"NN Accuracy = \", nn_acc)\n",
    "    print(\"-------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save accuracies on disk\n",
    "with open(os.path.join(project_path,\"accuracies.pickle\"), \"wb\") as f:\n",
    "    pickle.dump((val_accs,train_accs,nn_accs),f)\n",
    "    \n",
    "#Load accuraces from disk\n",
    "with open(os.path.join(project_path, \"accuracies.pickle\"), \"rb\") as f:\n",
    "    (val_accs, train_accs, nn_accs) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_images(X):\n",
    "    \"\"\"Concatenates a bunch of images into a big matrix for plotting purposes.\"\"\"\n",
    "    nc, h , w, _ = X.shape\n",
    "    X = X.reshape(nc, h, w)\n",
    "    n = np.ceil(np.sqrt(nc)).astype(\"int8\")\n",
    "    img = np.zeros((n*h,n*w))\n",
    "    x = 0\n",
    "    y = 0\n",
    "    for example in range(nc):\n",
    "        img[x*h:(x+1)*h,y*w:(y+1)*w] = X[example]\n",
    "        y += 1\n",
    "        if y >= n:\n",
    "            y = 0\n",
    "            x += 1\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_oneshot_task(pairs):\n",
    "    fig,(ax1,ax2) = plt.subplots(nrows=1, ncols=2, figsize=(15,15))\n",
    "    ax1.matshow(pairs[0][0].reshape(30,2), cmap='gray')\n",
    "    img = concat_images(pairs[1])\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax2.matshow(img,cmap='gray')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of concat image visualization\n",
    "pairs, targets = training_pipeline.make_oneshot_task(1,pos_train,neg_train,spoof_ground_truth.spoof_step1_truth1)\n",
    "plot_oneshot_task(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "ax.plot(ways, val_accs, \"m\", label=\"Siamese(val set)\")\n",
    "ax.plot(ways, train_accs, \"y\", label=\"Siamese(train set)\")\n",
    "plt.plot(ways, nn_accs, label=\"Nearest neighbour\")\n",
    "\n",
    "ax.plot(ways, 100.0/ways, \"g\", label=\"Random guessing\")\n",
    "plt.xlabel(\"Number of possible classes in one-shot tasks\")\n",
    "plt.ylabel(\"% Accuracy\")\n",
    "plt.title(\"Omiglot One-Shot Learning Performance of a Siamese Network\")\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "#inputs,targets = make_oneshot_task(20, \"val\", 'Oriya')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "def _normalize_img(img, label):\n",
    "    img = tf.cast(img, tf.float32) / 255.\n",
    "    return (img, label)\n",
    "\n",
    "train_dataset, test_dataset = tfds.load(name=\"mnist\", split=['train', 'test'], as_supervised=True)\n",
    "\n",
    "# Build your input pipelines\n",
    "train_dataset = train_dataset.shuffle(1024).batch(32)\n",
    "train_dataset = train_dataset.map(_normalize_img)\n",
    "\n",
    "test_dataset = test_dataset.batch(32)\n",
    "test_dataset = test_dataset.map(_normalize_img)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation=None), # No activation on final dense layer\n",
    "    tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n",
    "\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tfa.losses.TripletSemiHardLoss())\n",
    "\n",
    "# Train the network\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=5)\n",
    "\n",
    "# Evaluate the network\n",
    "results = model.predict(test_dataset)\n",
    "\n",
    "# Save test embeddings for visualization in projector\n",
    "np.savetxt(\"vecs.tsv\", results, delimiter='\\t')\n",
    "\n",
    "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "for img, labels in tfds.as_numpy(test_dataset):\n",
    "    [out_m.write(str(x) + \"\\n\") for x in labels]\n",
    "out_m.close()\n",
    "\n",
    "\n",
    "\n",
    "from google.colab import files\n",
    "files.download('vecs.tsv')\n",
    "files.download('meta.tsv')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasons for Choices\n",
    "Normalisation - https://stats.stackexchange.com/questions/7757/data-normalization-and-standardization-in-neural-networks\n",
    "https://medium.com/@urvashilluniya/why-data-normalization-is-necessary-for-machine-learning-models-681b65a05029\n",
    "https://towardsdatascience.com/why-data-should-be-normalized-before-training-a-neural-network-c626b7f66c7d\n",
    "https://www.jeremyjordan.me/batch-normalization/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spoofing_new]",
   "language": "python",
   "name": "conda-env-spoofing_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
